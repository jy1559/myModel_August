{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45ddc39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['data'])\n"
     ]
    }
   ],
   "source": [
    "import dataset as dataset\n",
    "\n",
    "train_loader, val_loader, test_loader = dataset.get_dataloaders(dataset_folder = '/home/jy1559/Mar2025_Module/Datasets',\n",
    "                                            dataset_name='Globo',\n",
    "                                              train_batch_th=10000,\n",
    "                                              use_bucket_batching=True,\n",
    "                                              use_add_info=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f364101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'Globo'\n",
    "if dataset_name == 'Globo':\n",
    "    add_info_num_cat = [('cat', 11), ('cat', 4), ('cat', 4), ('cat', 20), ('cat', 7), ('cat', 28)]\n",
    "elif dataset_name == 'LFM-BeyMS':\n",
    "    add_info_num_cat = []\n",
    "elif dataset_name == 'Retail_Rocket':\n",
    "    add_info_num_cat = [('cat', 3), ('num', -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa6b4f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['item_id', 'interaction_mask', 'session_mask', 'add_info', 'delta_ts'])\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_loader)).keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e57ea63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset as dataset\n",
    "llm_embedding = dataset.get_llm_embedding(dataset_folder = '/home/jy1559/Mar2025_Module/Datasets',\n",
    "                                            dataset_name='Globo',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ea6fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46034\n"
     ]
    }
   ],
   "source": [
    "print(llm_embedding['embedding_tensor'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c75adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_items = llm_embedding['embedding_tensor'].shape[0]\n",
    "input_embedding_config = {\n",
    "    'dt_method': 'bucket',\n",
    "    'num_buckets': 32,\n",
    "    'bucket_size': 2,\n",
    "    'use_add_info': True,\n",
    "    'add_info_specs': add_info_num_cat,\n",
    "    'dataset_folder' : '/home/jy1559/Mar2025_Module/Datasets',\n",
    "    'dataset_name': 'Globo',\n",
    "    'use_llm': True,\n",
    "    'use_add_info': True,\n",
    "    'device' : 'cuda:3',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "def05504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID Embedding: 46034 items, 64 dim\n",
      "LLM Embedding: 46034 items, 250 dim\n"
     ]
    }
   ],
   "source": [
    "import model_code.input_embedding as input_embedding\n",
    "input_embedder = input_embedding.InputEmbedding(\n",
    "    n_items=num_items, **input_embedding_config)\n",
    "input_embedder = input_embedder.to('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "452c0d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID Embedding: 46034 items, 64 dim\n"
     ]
    }
   ],
   "source": [
    "import model_code.model as model\n",
    "model_config = {\n",
    "    'dataset_name': 'Globo',\n",
    "    'dt_method': 'bucket',\n",
    "    'num_buckets': 32,\n",
    "    'bucket_size': 2,\n",
    "    'use_add_info': False,\n",
    "    'use_llm': False,\n",
    "    'use_dt': False,\n",
    "    'num_layers': 2,\n",
    "    'hidden_size': 512,\n",
    "    'num_heads': 8,\n",
    "    'dropout': 0.1,\n",
    "    'add_info_specs': add_info_num_cat,\n",
    "    'device': 'cuda:3',\n",
    "}\n",
    "mod = model.SeqRecModel(num_items, model_config).to('cuda:3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18542290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "batch = next(iter(train_loader))\n",
    "batch = {k: v.to(\"cuda:3\") if torch.is_tensor(v) else v  for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99cf77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c5f0716c1b4144a82d84ae15e5dc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2706 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch processed in 1.4297 seconds, loss = 5.8161\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from loss import compute_loss\n",
    "from tqdm.auto import tqdm\n",
    "import os, torch\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "i = 0\n",
    "for batch in tqdm(train_loader, total=len(train_loader)):\n",
    "    start_time = time()\n",
    "    batch = {k: v.to(\"cuda:3\") if torch.is_tensor(v) else v for k, v in batch.items()}\n",
    "    out = mod(batch)\n",
    "    loss = compute_loss(batch, out, mod, {'dataset_name': 'Globo'})\n",
    "    end_time = time()\n",
    "    if i % 500 == 0: print(f\"Batch processed in {end_time - start_time:.4f} seconds, loss = {loss.item():.4f}\")\n",
    "    i += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b5d38",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict' object is not an iterator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:3\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_tensor(v) \u001b[38;5;28;01melse\u001b[39;00m v  \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m      3\u001b[0m mod(batch)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict' object is not an iterator"
     ]
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "batch = {k: v.to(\"cuda:3\") if torch.is_tensor(v) else v  for k, v in batch.items()}\n",
    "mod(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae4854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([46034, 384])\n",
      "torch.Size([364047, 384])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "with open('/home/jy1559/Mar2025_Module/Datasets/Globo/item_embedding_dense.pickle', 'rb') as f:\n",
    "    item_embedding_dense = pickle.load(f)\n",
    "with open('/home/jy1559/Mar2025_Module/Datasets/Globo/item_embedding_normalized_revised.pickle', 'rb') as f:\n",
    "    item_embedding_revised = pickle.load(f)\n",
    "print(item_embedding_dense['embedding_tensor'].shape)\n",
    "print(item_embedding_revised['embedding_tensor'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f03a516",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m session_encoder_model \u001b[38;5;241m=\u001b[39m session_encoder\u001b[38;5;241m.\u001b[39mSessionEncoder()\n\u001b[1;32m      3\u001b[0m session_encoder_model \u001b[38;5;241m=\u001b[39m session_encoder_model\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:3\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m usr_embedding \u001b[38;5;241m=\u001b[39m \u001b[43minput_embedding\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m sesseion_encoder_output, user_embedding_input, loss_mask \u001b[38;5;241m=\u001b[39m session_encoder_model(input_embedding[:, \u001b[38;5;241m0\u001b[39m, :, :],\n\u001b[1;32m      6\u001b[0m                batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minteraction_mask\u001b[39m\u001b[38;5;124m'\u001b[39m][:, \u001b[38;5;241m0\u001b[39m, :]\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:3\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m      7\u001b[0m                usr_embedding\u001b[38;5;241m=\u001b[39musr_embedding,)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import model_code.session_encoder as session_encoder\n",
    "session_encoder_model = session_encoder.SessionEncoder()\n",
    "session_encoder_model = session_encoder_model.to('cuda:3')\n",
    "usr_embedding = input_embedding[:, 0, 0, :]\n",
    "sesseion_encoder_output, user_embedding_input, loss_mask = session_encoder_model(input_embedding[:, 0, :, :],\n",
    "               batch['interaction_mask'][:, 0, :].to('cuda:3'),\n",
    "               usr_embedding=usr_embedding,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff132d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 256])\n",
      "torch.Size([6, 26, 8])\n",
      "prev_state shape: torch.Size([1, 6, 256])\n",
      "pad_mask) shape: torch.Size([6])\n",
      "dt_sec shape: torch.Size([6])\n",
      "dt_emb shape: torch.Size([6, 16])\n",
      "session_vec shape: torch.Size([6, 256])\n",
      "x_t shape: torch.Size([6, 1, 272])\n",
      "x_t shape: torch.Size([6, 1, 272])\n",
      "prev_state shape: torch.Size([1, 6, 256])\n",
      "torch.Size([1, 6, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model_code.user_update import UserStateUpdater\n",
    "B, D_sess = 4, 256\n",
    "sess_vec   = torch.randn(B, D_sess).to('cuda:3')\n",
    "delta_t    = torch.tensor([30., 3600., 180., 600.]).to('cuda:3')  # 초 단위\n",
    "\n",
    "updater = UserStateUpdater(d_session=D_sess,\n",
    "                           method='default',\n",
    "                           rnn='GRU',\n",
    "                           device='cuda:3',\n",
    "                           dt_emb_module=input_embedder.dt_emb,)\n",
    "\n",
    "state_0 = updater.reset_state(batch['delta_ts'].shape[0], 'cuda:3')\n",
    "print(user_embedding_input.shape)  # [B, D_sess]\n",
    "print(batch['delta_ts'].to('cuda:3').shape) # [B, S, I]\n",
    "state_1 = updater(user_embedding_input, state_0, dt_sec=batch['delta_ts'][:, 0, 0].to('cuda:3'), pad_mask=batch['interaction_mask'][:, 0, 0].to('cuda:3'))\n",
    "\n",
    "print(state_1.shape)   # GRU → [1,B,hidden]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa19a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "first",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
